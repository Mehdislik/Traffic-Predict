{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/o1ritEa04u+RZmsGOh4i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mehdislik/Traffic-Predict/blob/main/traffic-prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tunM0iQqUXrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5902e66b-22d0-4ad6-ef1a-e8c464d3f3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dateparser\n",
            "  Downloading dateparser-1.2.2-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2025.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (5.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->dateparser) (1.17.0)\n",
            "Downloading dateparser-1.2.2-py3-none-any.whl (315 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/315.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dateparser\n",
            "Successfully installed dateparser-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install dateparser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data cleaning\n",
        "import pandas as pd\n",
        "import dateparser\n",
        "\n",
        "df = pd.read_csv(\"histo_trafic.csv\", encoding=\"ISO-8859-1\", sep=\";\")\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "df = df[[\"secteur\", \"site\", \"tstamp\", \"trafic_mbps\"]]\n",
        "df[\"trafic_mbps\"] = df[\"trafic_mbps\"].astype(str).str.replace(\",\", \".\", regex=False)\n",
        "df[\"trafic_mbps\"] = pd.to_numeric(df[\"trafic_mbps\"], errors=\"coerce\")\n",
        "df[\"tstamp\"] = df[\"tstamp\"].apply(lambda x: dateparser.parse(str(x), languages=['fr']))\n",
        "df = df.dropna(subset=[\"tstamp\", \"trafic_mbps\"])\n",
        "df = df.sort_values(by=[\"secteur\", \"tstamp\"])\n",
        "print(df.head())\n",
        "df.to_csv(\"histo_trafic_cleaned.csv\", index=False, encoding=\"utf-8\")\n"
      ],
      "metadata": {
        "id": "LNPsE5vcUnlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5efa1c88-60a5-4955-8317-5a3dcc76925a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      secteur    site     tstamp  trafic_mbps\n",
            "1575  T36870A  T36870 2018-11-12     0.263481\n",
            "1658  T36870A  T36870 2018-11-19     0.066913\n",
            "1741  T36870A  T36870 2018-11-26     0.062066\n",
            "1824  T36870A  T36870 2018-12-03     0.084320\n",
            "1907  T36870A  T36870 2018-12-10     0.047759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install statsmodels psutil -q"
      ],
      "metadata": {
        "id": "3G8wActqWIx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. IMPORTS\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import psutil\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 3. UTILITY FUNCTIONS\n",
        "def count_arima_operations(p, d, q, n_obs):\n",
        "    \"\"\"\n",
        "    Calculate FLOPS for ARIMA(p,d,q) using analytical formula:\n",
        "    O(n · (p² + q²))\n",
        "    where n is series length, p is AR order, q is MA order\n",
        "    \"\"\"\n",
        "    # Analytical formula\n",
        "    flops = n_obs * (p**2 + q**2)\n",
        "    return flops\n",
        "\n",
        "def safe_cpu_measure():\n",
        "    \"\"\"CPU measurement adapted for Colab\"\"\"\n",
        "    try:\n",
        "        # Measure over short period to avoid conflicts\n",
        "        return psutil.cpu_percent(interval=0.1)\n",
        "    except:\n",
        "        return 0  # Fallback if issues\n",
        "\n",
        "# 4. DATA VERIFICATION\n",
        "print(\" Data verification...\")\n",
        "print(f\"DataFrame shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(f\"Number of unique sectors: {df['secteur'].nunique()}\")\n",
        "print(f\"Data sample:\")\n",
        "print(df.head(3))\n",
        "\n",
        "# 5. MAIN ARIMA ANALYSIS\n",
        "print(\"\\n Starting ARIMA analysis...\")\n",
        "\n",
        "arima_results = []\n",
        "grouped = df.groupby(\"secteur\")\n",
        "total_sectors = len(grouped)\n",
        "\n",
        "# Manual progress bar\n",
        "processed = 0\n",
        "errors = 0\n",
        "\n",
        "for sector, data in grouped:\n",
        "    processed += 1\n",
        "\n",
        "    # Progress display\n",
        "    if processed % 100 == 0 or processed in [1, 10, 50]:\n",
        "        print(f\" Progress: {processed}/{total_sectors} sectors ({processed/total_sectors*100:.1f}%)\")\n",
        "\n",
        "    # Data preparation\n",
        "    y = data.sort_values(\"tstamp\")[\"trafic_mbps\"].values\n",
        "    if len(y) <= 10:  # Skip if not enough data\n",
        "        continue\n",
        "\n",
        "    train, test = y[:-1], y[-1]\n",
        "\n",
        "    try:\n",
        "        # STEP 1: FITTING (training)\n",
        "        cpu_before_fit = safe_cpu_measure()\n",
        "        fit_start = time.perf_counter()  # More precise than time.time()\n",
        "\n",
        "        model = ARIMA(train, order=(2,1,2))\n",
        "        fitted_model = model.fit(method_kwargs={\"warn_convergence\": False})\n",
        "\n",
        "        fit_time = time.perf_counter() - fit_start\n",
        "        cpu_after_fit = safe_cpu_measure()\n",
        "\n",
        "        # STEP 2: INFERENCE (pure prediction)\n",
        "        cpu_before_inf = safe_cpu_measure()\n",
        "        inference_start = time.perf_counter()\n",
        "\n",
        "        pred = float(fitted_model.forecast()[0])\n",
        "\n",
        "        inference_time = time.perf_counter() - inference_start\n",
        "        cpu_after_inf = safe_cpu_measure()\n",
        "\n",
        "        # METRICS CALCULATION\n",
        "        rmse = float(np.sqrt(mean_squared_error([test], [pred])))\n",
        "\n",
        "        #  FLOPS calculation: O(n · (p² + q²))\n",
        "        flops = count_arima_operations(p=2, d=1, q=2, n_obs=len(train))\n",
        "\n",
        "        # Power (average CPU measurements)\n",
        "        avg_cpu_fit = (cpu_before_fit + cpu_after_fit) / 2\n",
        "        avg_cpu_inf = (cpu_before_inf + cpu_after_inf) / 2\n",
        "\n",
        "        # Store results\n",
        "        arima_results.append({\n",
        "            \"sector\": sector,\n",
        "            \"actual_value\": float(test),\n",
        "            \"predicted_value\": pred,\n",
        "            \"RMSE\": rmse,\n",
        "            \"fit_time_s\": fit_time,\n",
        "            \"inference_time_s\": inference_time,\n",
        "            \"total_time_s\": fit_time + inference_time,\n",
        "            \"FLOPS_estimated\": flops,\n",
        "            \"cpu_fit_percent\": avg_cpu_fit,\n",
        "            \"cpu_inference_percent\": avg_cpu_inf,\n",
        "            \"n_observations\": len(train)\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        errors += 1\n",
        "        if errors <= 5:  # Show only first 5 errors\n",
        "            print(f\" Error sector {sector}: {str(e)[:50]}...\")\n",
        "        continue\n",
        "\n",
        "# 6. RESULTS ANALYSIS\n",
        "print(f\"\\n Analysis completed!\")\n",
        "print(f\"   • Successful predictions: {len(arima_results)}\")\n",
        "print(f\"   • Errors: {errors}\")\n",
        "print(f\"   • Success rate: {len(arima_results)/(len(arima_results)+errors)*100:.1f}%\")\n",
        "\n",
        "if len(arima_results) == 0:\n",
        "    print(\" No successful predictions!\")\n",
        "else:\n",
        "    # Create final DataFrame\n",
        "    df_arima = pd.DataFrame(arima_results)\n",
        "\n",
        "    # GLOBAL METRICS\n",
        "    global_rmse = np.sqrt(np.mean(df_arima[\"RMSE\"]**2))\n",
        "    avg_inference_time = df_arima[\"inference_time_s\"].mean()\n",
        "    avg_flops = df_arima[\"FLOPS_estimated\"].mean()\n",
        "    avg_power_inference = df_arima[\"cpu_inference_percent\"].mean()\n",
        "\n",
        "    # 7. FINAL RESULTS\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ARIMA RESULTS - PROJECT METRICS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\" Global RMSE: {global_rmse:.4f}\")\n",
        "    print(f\"  Average inference time: {avg_inference_time:.6f} seconds\")\n",
        "    print(f\" Average FLOPS: {avg_flops:.0f} operations\")\n",
        "    print(f\" Average CPU (inference): {avg_power_inference:.1f}%\")\n",
        "    print(f\" Number of antennas: {len(df_arima)}\")\n",
        "\n",
        "    # Detailed statistics\n",
        "    print(f\"\\n Detailed statistics:\")\n",
        "    print(f\"   • RMSE min/max: {df_arima['RMSE'].min():.4f} / {df_arima['RMSE'].max():.4f}\")\n",
        "    print(f\"   • Inference time min/max: {df_arima['inference_time_s'].min():.6f}s / {df_arima['inference_time_s'].max():.6f}s\")\n",
        "\n",
        "    # 8. SAVE RESULTS\n",
        "    df_arima_sorted = df_arima.sort_values(\"RMSE\")\n",
        "    df_arima_sorted.to_csv(\"ARIMA_complete_results.csv\", index=False)\n",
        "    print(f\"\\n File saved: ARIMA_complete_results.csv\")\n",
        "\n",
        "    # 9. SUMMARY FOR FINAL COMPARISON\n",
        "    arima_summary = {\n",
        "        \"model\": \"ARIMA(2,1,2)\",\n",
        "        \"global_rmse\": global_rmse,\n",
        "        \"avg_inference_time_s\": avg_inference_time,\n",
        "        \"avg_flops\": avg_flops,\n",
        "        \"avg_power_cpu_percent\": avg_power_inference,\n",
        "        \"n_predictions\": len(df_arima),\n",
        "        \"success_rate_percent\": len(arima_results)/(len(arima_results)+errors)*100\n",
        "    }\n",
        "\n",
        "    print(f\"\\n Summary stored in 'arima_summary' for comparison!\")\n",
        "\n",
        "    # Preview of best/worst predictions with timing\n",
        "    print(f\"\\n Top 5 best predictions (lowest RMSE):\")\n",
        "    print(df_arima_sorted[[\"sector\", \"actual_value\", \"predicted_value\", \"RMSE\", \"inference_time_s\"]].head().to_string(index=False))\n",
        "\n",
        "    print(f\"\\n Top 5 worst predictions (highest RMSE):\")\n",
        "    print(df_arima_sorted[[\"sector\", \"actual_value\", \"predicted_value\", \"RMSE\", \"inference_time_s\"]].tail().to_string(index=False))\n",
        "\n",
        "print(f\"\\n ARIMA analysis complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpuPPUllVDX-",
        "outputId": "601ef8f9-097b-4264-af90-d642ece22e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Data verification...\n",
            "DataFrame shape: (24486, 4)\n",
            "Columns: ['secteur', 'site', 'tstamp', 'trafic_mbps']\n",
            "Number of unique sectors: 86\n",
            "Data sample:\n",
            "      secteur    site     tstamp  trafic_mbps\n",
            "1575  T36870A  T36870 2018-11-12     0.263481\n",
            "1658  T36870A  T36870 2018-11-19     0.066913\n",
            "1741  T36870A  T36870 2018-11-26     0.062066\n",
            "\n",
            "🚀 Starting ARIMA analysis...\n",
            "📊 Progress: 1/86 sectors (1.2%)\n",
            "📊 Progress: 10/86 sectors (11.6%)\n",
            "📊 Progress: 50/86 sectors (58.1%)\n",
            "\n",
            "✅ Analysis completed!\n",
            "   • Successful predictions: 86\n",
            "   • Errors: 0\n",
            "   • Success rate: 100.0%\n",
            "\n",
            "==================================================\n",
            "📈 ARIMA RESULTS - PROJECT METRICS\n",
            "==================================================\n",
            "🎯 Global RMSE: 7.7527\n",
            "⏱️  Average inference time: 0.001493 seconds\n",
            "🔥 Average FLOPS: 2270 operations\n",
            "⚡ Average CPU (inference): 5.3%\n",
            "📊 Number of antennas: 86\n",
            "\n",
            "📋 Detailed statistics:\n",
            "   • RMSE min/max: 0.0222 / 32.9842\n",
            "   • Inference time min/max: 0.001254s / 0.002572s\n",
            "\n",
            "💾 File saved: ARIMA_complete_results.csv\n",
            "\n",
            "🎯 Summary stored in 'arima_summary' for comparison!\n",
            "\n",
            "🏆 Top 5 best predictions (lowest RMSE):\n",
            " sector  actual_value  predicted_value     RMSE  inference_time_s\n",
            "T78279B      2.469312         2.447106 0.022206          0.001416\n",
            "T36870B      5.575435         5.540694 0.034742          0.001448\n",
            "T78273A     21.785697        21.915640 0.129944          0.001858\n",
            "T78256C     53.650128        53.506445 0.143684          0.001640\n",
            "T70721A      3.751871         3.599890 0.151981          0.001533\n",
            "\n",
            "⚠️ Top 5 worst predictions (highest RMSE):\n",
            " sector  actual_value  predicted_value      RMSE  inference_time_s\n",
            "T78269A     85.475880        72.105563 13.370317          0.001429\n",
            "T78259C     75.051396        52.452817 22.598579          0.001495\n",
            "T78273C    106.270507        79.552524 26.717983          0.001710\n",
            "T78258B     93.256429        64.704510 28.551919          0.001557\n",
            "T70744B     98.002783        65.018626 32.984156          0.001394\n",
            "\n",
            "🎉 ARIMA analysis complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. INSTALLATIONS\n",
        "!pip install tensorflow psutil -q"
      ],
      "metadata": {
        "id": "zyMSDOcTaEW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import psutil\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# 3. UTILITY FUNCTIONS\n",
        "def make_sequences(arr, window=5):\n",
        "    \"\"\"Create sequences for LSTM training\"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(arr) - window):\n",
        "        X.append(arr[i:i+window])\n",
        "        y.append(arr[i+window])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "    return X, y\n",
        "\n",
        "def count_lstm_flops(model, sequence_length, batch_size=1):\n",
        "    \"\"\"\n",
        "    Calculate FLOPS for LSTM using analytical formula:\n",
        "    FLOPS ≈ 4 × (h² + h·x + h) × timesteps\n",
        "    where h is hidden units, x is input features, timesteps is sequence length\n",
        "    \"\"\"\n",
        "    lstm_units = 50  # From model architecture (h)\n",
        "    input_size = 1   # Single feature (x)\n",
        "    timesteps = sequence_length\n",
        "\n",
        "    # Analytical formula from project specification\n",
        "    # FLOPS ≈ 4 × (h² + h·x + h) × timesteps\n",
        "    flops = 4 * (lstm_units**2 + lstm_units * input_size + lstm_units) * timesteps\n",
        "\n",
        "    return flops\n",
        "\n",
        "def safe_cpu_measure():\n",
        "    \"\"\"CPU measurement \"\"\"\n",
        "    try:\n",
        "        return psutil.cpu_percent(interval=0.1)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "# 4. LSTM PARAMETERS\n",
        "window_size = 5\n",
        "epochs = 50\n",
        "batch_size = 8\n",
        "\n",
        "print(\"Data verification...\")\n",
        "print(f\"DataFrame shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(f\"Number of unique sectors: {df['secteur'].nunique()}\")\n",
        "\n",
        "# 5. MAIN LSTM ANALYSIS\n",
        "print(f\"\\n Starting LSTM analysis...\")\n",
        "print(f\"   • Window size: {window_size}\")\n",
        "print(f\"   • Epochs: {epochs}\")\n",
        "print(f\"   • Batch size: {batch_size}\")\n",
        "\n",
        "lstm_results = []\n",
        "grouped = df.groupby(\"secteur\")\n",
        "total_sectors = len(grouped)\n",
        "\n",
        "processed = 0\n",
        "errors = 0\n",
        "\n",
        "# Suppress TensorFlow warnings\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "for sector, data in grouped:\n",
        "    processed += 1\n",
        "\n",
        "    # Progress display\n",
        "    if processed % 50 == 0 or processed in [1, 10, 25]:\n",
        "        print(f\"Progress: {processed}/{total_sectors} sectors ({processed/total_sectors*100:.1f}%)\")\n",
        "\n",
        "    # Data preparation\n",
        "    serie = data.sort_values(\"tstamp\")[\"trafic_mbps\"].values\n",
        "    if len(serie) <= window_size + 1:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Data scaling\n",
        "        scaler = MinMaxScaler()\n",
        "        y_scaled = scaler.fit_transform(serie.reshape(-1,1)).flatten()\n",
        "\n",
        "        # Create sequences\n",
        "        X, y = make_sequences(y_scaled, window=window_size)\n",
        "        if len(y) < 2:\n",
        "            continue\n",
        "\n",
        "        # Train/test split (last point for testing)\n",
        "        X_train, y_train = X[:-1], y[:-1]\n",
        "        X_test, y_test = X[-1:], y[-1:]\n",
        "\n",
        "        # STEP 1: MODEL CREATION AND TRAINING\n",
        "        cpu_before_train = safe_cpu_measure()\n",
        "        train_start = time.perf_counter()\n",
        "\n",
        "        model = Sequential([\n",
        "            LSTM(50, activation='relu', input_shape=(window_size, 1)),\n",
        "            Dense(1)\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "        # Training (with progress suppressed)\n",
        "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "        train_time = time.perf_counter() - train_start\n",
        "        cpu_after_train = safe_cpu_measure()\n",
        "\n",
        "        # STEP 2: INFERENCE (pure prediction)\n",
        "        cpu_before_inf = safe_cpu_measure()\n",
        "        inference_start = time.perf_counter()\n",
        "\n",
        "        y_pred = model.predict(X_test, verbose=0)\n",
        "\n",
        "        inference_time = time.perf_counter() - inference_start\n",
        "        cpu_after_inf = safe_cpu_measure()\n",
        "\n",
        "        # STEP 3: METRICS CALCULATION\n",
        "        # Inverse scaling\n",
        "        y_test_inv = scaler.inverse_transform(y_test.reshape(-1,1)).flatten()[0]\n",
        "        y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1,1)).flatten()[0]\n",
        "\n",
        "        # RMSE\n",
        "        rmse = float(np.sqrt(mean_squared_error([y_test_inv], [y_pred_inv])))\n",
        "\n",
        "        # CORRECTED FLOPS estimation: 4 × (h² + h·x + h) × timesteps\n",
        "        flops = count_lstm_flops(model, window_size)\n",
        "\n",
        "        # Power (CPU averages)\n",
        "        avg_cpu_train = (cpu_before_train + cpu_after_train) / 2\n",
        "        avg_cpu_inf = (cpu_before_inf + cpu_after_inf) / 2\n",
        "\n",
        "        # Store results\n",
        "        lstm_results.append({\n",
        "            \"sector\": sector,\n",
        "            \"actual_value\": float(y_test_inv),\n",
        "            \"predicted_value\": float(y_pred_inv),\n",
        "            \"RMSE\": rmse,\n",
        "            \"train_time_s\": train_time,\n",
        "            \"inference_time_s\": inference_time,\n",
        "            \"total_time_s\": train_time + inference_time,\n",
        "            \"FLOPS_estimated\": flops,\n",
        "            \"cpu_train_percent\": avg_cpu_train,\n",
        "            \"cpu_inference_percent\": avg_cpu_inf,\n",
        "            \"n_observations\": len(serie),\n",
        "            \"sequence_length\": window_size\n",
        "        })\n",
        "\n",
        "        # Clean up model to free memory\n",
        "        del model\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    except Exception as e:\n",
        "        errors += 1\n",
        "        if errors <= 5:  # Show only first 5 errors\n",
        "            print(f\"Error sector {sector}: {str(e)[:50]}...\")\n",
        "        continue\n",
        "\n",
        "# 6. RESULTS ANALYSIS\n",
        "print(f\"\\n LSTM analysis completed!\")\n",
        "print(f\"   • Successful predictions: {len(lstm_results)}\")\n",
        "print(f\"   • Errors: {errors}\")\n",
        "print(f\"   • Success rate: {len(lstm_results)/(len(lstm_results)+errors)*100:.1f}%\")\n",
        "\n",
        "if len(lstm_results) == 0:\n",
        "    print(\" No successful predictions!\")\n",
        "else:\n",
        "    # Create final DataFrame\n",
        "    df_lstm = pd.DataFrame(lstm_results)\n",
        "\n",
        "    # GLOBAL METRICS (as requested in project)\n",
        "    global_rmse = np.sqrt(np.mean(df_lstm[\"RMSE\"]**2))\n",
        "    avg_inference_time = df_lstm[\"inference_time_s\"].mean()\n",
        "    avg_train_time = df_lstm[\"train_time_s\"].mean()\n",
        "    avg_flops = df_lstm[\"FLOPS_estimated\"].mean()\n",
        "    avg_power_inference = df_lstm[\"cpu_inference_percent\"].mean()\n",
        "\n",
        "    # 7. FINAL RESULTS\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\" LSTM RESULTS - PROJECT METRICS\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\" Global RMSE: {global_rmse:.4f}\")\n",
        "    print(f\"  Average inference time: {avg_inference_time:.6f} seconds\")\n",
        "    print(f\"  Average training time: {avg_train_time:.3f} seconds\")\n",
        "    print(f\" Average FLOPS: {avg_flops:.0f} operations\")\n",
        "    print(f\" Average CPU (inference): {avg_power_inference:.1f}%\")\n",
        "    print(f\" Number of antennas: {len(df_lstm)}\")\n",
        "\n",
        "    # Detailed statistics\n",
        "    print(f\"\\n Detailed statistics:\")\n",
        "    print(f\"   • RMSE min/max: {df_lstm['RMSE'].min():.4f} / {df_lstm['RMSE'].max():.4f}\")\n",
        "    print(f\"   • Inference time min/max: {df_lstm['inference_time_s'].min():.6f}s / {df_lstm['inference_time_s'].max():.6f}s\")\n",
        "    print(f\"   • Training time min/max: {df_lstm['train_time_s'].min():.3f}s / {df_lstm['train_time_s'].max():.3f}s\")\n",
        "\n",
        "    # 8. SAVE RESULTS\n",
        "    df_lstm_sorted = df_lstm.sort_values(\"RMSE\")\n",
        "    df_lstm_sorted.to_csv(\"LSTM_complete_results.csv\", index=False)\n",
        "    print(f\"\\n File saved: LSTM_complete_results.csv\")\n",
        "\n",
        "    # 9. SUMMARY FOR FINAL COMPARISON\n",
        "    lstm_summary = {\n",
        "        \"model\": \"LSTM(50_units)\",\n",
        "        \"global_rmse\": global_rmse,\n",
        "        \"avg_inference_time_s\": avg_inference_time,\n",
        "        \"avg_train_time_s\": avg_train_time,\n",
        "        \"avg_flops\": avg_flops,\n",
        "        \"avg_power_cpu_percent\": avg_power_inference,\n",
        "        \"n_predictions\": len(df_lstm),\n",
        "        \"success_rate_percent\": len(lstm_results)/(len(lstm_results)+errors)*100,\n",
        "        \"window_size\": window_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    print(f\"\\n Summary stored in 'lstm_summary' for comparison!\")\n",
        "\n",
        "    # Preview of best/worst predictions with timing\n",
        "    print(f\"\\n Top 5 best predictions (lowest RMSE):\")\n",
        "    print(df_lstm_sorted[[\"sector\", \"actual_value\", \"predicted_value\", \"RMSE\", \"inference_time_s\"]].head().to_string(index=False))\n",
        "\n",
        "    print(f\"\\n Top 5 worst predictions (highest RMSE):\")\n",
        "    print(df_lstm_sorted[[\"sector\", \"actual_value\", \"predicted_value\", \"RMSE\", \"inference_time_s\"]].tail().to_string(index=False))\n",
        "\n",
        "    # Model complexity info\n",
        "    print(f\"\\n Model complexity:\")\n",
        "    print(f\"   • LSTM units: 50\")\n",
        "    print(f\"   • Input sequence length: {window_size}\")\n",
        "    print(f\"   • Training epochs: {epochs}\")\n",
        "    print(f\"   • Estimated parameters: ~10,000\")\n",
        "\n",
        "print(f\"\\n LSTM analysis complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VGctrIxSZiFJ",
        "outputId": "d0d0d64f-a7c7-4378-86ae-942bd015f08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Data verification...\n",
            "DataFrame shape: (24486, 4)\n",
            "Columns: ['secteur', 'site', 'tstamp', 'trafic_mbps']\n",
            "Number of unique sectors: 86\n",
            "\n",
            "🚀 Starting LSTM analysis...\n",
            "   • Window size: 5\n",
            "   • Epochs: 50\n",
            "   • Batch size: 8\n",
            "📊 Progress: 1/86 sectors (1.2%)\n",
            "📊 Progress: 10/86 sectors (11.6%)\n",
            "📊 Progress: 25/86 sectors (29.1%)\n",
            "📊 Progress: 50/86 sectors (58.1%)\n",
            "\n",
            "✅ LSTM analysis completed!\n",
            "   • Successful predictions: 86\n",
            "   • Errors: 0\n",
            "   • Success rate: 100.0%\n",
            "\n",
            "==================================================\n",
            "📈 LSTM RESULTS - PROJECT METRICS\n",
            "==================================================\n",
            "🎯 Global RMSE: 7.6592\n",
            "⏱️  Average inference time: 0.458046 seconds\n",
            "🏋️  Average training time: 8.878 seconds\n",
            "🔥 Average FLOPS: 52000 operations\n",
            "⚡ Average CPU (inference): 1.5%\n",
            "📊 Number of antennas: 86\n",
            "\n",
            "📋 Detailed statistics:\n",
            "   • RMSE min/max: 0.0382 / 29.8227\n",
            "   • Inference time min/max: 0.448031s / 0.468795s\n",
            "   • Training time min/max: 8.553s / 9.028s\n",
            "\n",
            "💾 File saved: LSTM_complete_results.csv\n",
            "\n",
            "🎯 Summary stored in 'lstm_summary' for comparison!\n",
            "\n",
            "🏆 Top 5 best predictions (lowest RMSE):\n",
            " sector  actual_value  predicted_value     RMSE  inference_time_s\n",
            "T78279B      2.469312         2.431139 0.038173          0.459772\n",
            "T70747A     12.251433        12.306964 0.055531          0.463450\n",
            "T70725B     48.305546        48.243984 0.061562          0.451236\n",
            "T70735B     20.981777        20.848330 0.133447          0.456047\n",
            "T70730A     44.049159        43.914127 0.135032          0.456310\n",
            "\n",
            "⚠️ Top 5 worst predictions (highest RMSE):\n",
            " sector  actual_value  predicted_value      RMSE  inference_time_s\n",
            "T70725A     39.343833        53.138123 13.794290          0.458764\n",
            "T78259C     75.051396        52.674446 22.376950          0.458413\n",
            "T78258B     93.256429        70.768341 22.488088          0.459432\n",
            "T70744B     98.002783        69.878418 28.124365          0.459823\n",
            "T78273C    106.270507        76.447769 29.822738          0.456131\n",
            "\n",
            "🏗️ Model complexity:\n",
            "   • LSTM units: 50\n",
            "   • Input sequence length: 5\n",
            "   • Training epochs: 50\n",
            "   • Estimated parameters: ~10,000\n",
            "\n",
            "🎉 LSTM analysis complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. INSTALLATIONS\n",
        "!pip install git+https://github.com/amazon-science/chronos-forecasting.git torch psutil -q"
      ],
      "metadata": {
        "id": "HQxcmoneesE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === CHRONOS BOLT CODE WITH COMPLETE PROJECT METRICS ===\n",
        "\n",
        "# 2. IMPORTS\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import psutil\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from chronos import BaseChronosPipeline\n",
        "\n",
        "# 3. UTILITY FUNCTIONS\n",
        "def rmse_np(y_true, y_pred):\n",
        "    \"\"\"RMSE calculation without sklearn dependency\"\"\"\n",
        "    y_true = np.asarray(y_true, dtype=np.float64)\n",
        "    y_pred = np.asarray(y_pred, dtype=np.float64)\n",
        "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
        "\n",
        "def safe_cpu_measure():\n",
        "    \"\"\"CPU measurement \"\"\"\n",
        "    try:\n",
        "        return psutil.cpu_percent(interval=0.1)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def count_transformer_flops(model, sequence_length, vocab_size_approx=32000):\n",
        "    \"\"\"\n",
        "    Estimate FLOPS for Transformer-based model (Chronos)\n",
        "    Based on attention mechanism and feed-forward operations\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get model parameters\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "        # Estimate based on typical transformer operations\n",
        "        # Attention: Q*K^T, softmax, attention*V\n",
        "        # Feed-forward: 2 linear layers\n",
        "\n",
        "        # Rough estimation: 2 * params * sequence_length\n",
        "        estimated_flops = 2 * total_params * sequence_length\n",
        "        return int(estimated_flops)\n",
        "    except:\n",
        "        # Fallback estimation based on model size\n",
        "        model_size_map = {\n",
        "            \"tiny\": 8_000_000,    # ~8M parameters\n",
        "            \"mini\": 20_000_000,   # ~20M parameters\n",
        "            \"small\": 46_000_000,  # ~46M parameters\n",
        "            \"base\": 200_000_000,  # ~200M parameters\n",
        "        }\n",
        "\n",
        "        # Extract size from model name\n",
        "        for size, params in model_size_map.items():\n",
        "            if size in str(model).lower():\n",
        "                return int(2 * params * sequence_length)\n",
        "\n",
        "        return 1_000_000  # Default fallback\n",
        "\n",
        "def get_model_size_mb(model):\n",
        "    \"\"\"Estimate model size in MB\"\"\"\n",
        "    try:\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        # Assuming float32: 4 bytes per parameter\n",
        "        size_mb = (total_params * 4) / (1024 ** 2)\n",
        "        return size_mb\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "# 4. DATA VERIFICATION\n",
        "print(\" Data verification...\")\n",
        "try:\n",
        "    df\n",
        "    print(f\"DataFrame loaded: {df.shape}\")\n",
        "except NameError:\n",
        "    df = pd.read_csv(\"histo_trafic_cleaned.csv\", parse_dates=[\"tstamp\"])\n",
        "    print(f\"DataFrame loaded from CSV: {df.shape}\")\n",
        "\n",
        "# Check required columns\n",
        "required_cols = {\"secteur\", \"tstamp\", \"trafic_mbps\"}\n",
        "missing = required_cols - set(df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing columns in df: {missing}\")\n",
        "\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(f\"Number of unique sectors: {df['secteur'].nunique()}\")\n",
        "\n",
        "# 5. MODEL CONFIGURATION\n",
        "models = [\n",
        "    \"amazon/chronos-bolt-tiny\",\n",
        "    \"amazon/chronos-bolt-mini\",\n",
        "    \"amazon/chronos-bolt-small\",\n",
        "    \"amazon/chronos-bolt-base\",\n",
        "]\n",
        "\n",
        "DEVICE_MAP = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "USE_BF16 = (DEVICE_MAP == \"cuda\")\n",
        "\n",
        "print(f\"\\n🔧 Configuration:\")\n",
        "print(f\"   • Device: {DEVICE_MAP}\")\n",
        "print(f\"   • BF16: {USE_BF16}\")\n",
        "print(f\"   • Models to test: {len(models)}\")\n",
        "\n",
        "# 6. MAIN CHRONOS ANALYSIS FUNCTION\n",
        "def run_bolt_for_model(model_name: str, df: pd.DataFrame, min_len: int = 6) -> dict:\n",
        "    \"\"\"Run Chronos model \"\"\"\n",
        "    print(f\"\\n Loading {model_name} on {DEVICE_MAP}...\")\n",
        "\n",
        "    # Model loading with timing\n",
        "    load_start = time.perf_counter()\n",
        "    cpu_before_load = safe_cpu_measure()\n",
        "\n",
        "    pipe = BaseChronosPipeline.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=DEVICE_MAP,\n",
        "        torch_dtype=(torch.bfloat16 if USE_BF16 else None),\n",
        "    )\n",
        "\n",
        "    load_time = time.perf_counter() - load_start\n",
        "    cpu_after_load = safe_cpu_measure()\n",
        "    model_device = next(pipe.model.parameters()).device\n",
        "\n",
        "    # Model info\n",
        "    model_size_mb = get_model_size_mb(pipe.model)\n",
        "    print(f\"   • Model size: {model_size_mb:.1f} MB\")\n",
        "    print(f\"   • Load time: {load_time:.3f}s\")\n",
        "\n",
        "    # Quantiles & median index\n",
        "    quantiles = getattr(pipe, \"quantiles\", [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
        "    median_idx = quantiles.index(0.5) if 0.5 in quantiles else 4\n",
        "\n",
        "    results = []\n",
        "    inference_times = []\n",
        "    cpu_measurements = []\n",
        "    flops_list = []\n",
        "\n",
        "    grouped = df.groupby(\"secteur\")\n",
        "    total_sectors = len(grouped)\n",
        "    processed = 0\n",
        "    errors = 0\n",
        "\n",
        "    print(f\"   • Processing {total_sectors} sectors...\")\n",
        "\n",
        "    for sector, data in grouped:\n",
        "        processed += 1\n",
        "\n",
        "        if processed % 100 == 0 or processed in [1, 10, 50]:\n",
        "            print(f\"     Progress: {processed}/{total_sectors} ({processed/total_sectors*100:.1f}%)\")\n",
        "\n",
        "        y = data.sort_values(\"tstamp\")[\"trafic_mbps\"].values.astype(np.float32)\n",
        "        if len(y) < (min_len + 1):\n",
        "            continue\n",
        "\n",
        "        true_last = float(y[-1])\n",
        "        history = y[:-1]\n",
        "\n",
        "        # Prepare context\n",
        "        context = torch.tensor(history, dtype=torch.float32).to(model_device)\n",
        "\n",
        "        try:\n",
        "            # INFERENCE\n",
        "            cpu_before_inf = safe_cpu_measure()\n",
        "            inference_start = time.perf_counter()\n",
        "\n",
        "            y_hat = pipe.predict(\n",
        "                context=context,\n",
        "                prediction_length=1,\n",
        "                limit_prediction_length=True,\n",
        "            )  # (1, 9, 1)\n",
        "\n",
        "            inference_time = time.perf_counter() - inference_start\n",
        "            cpu_after_inf = safe_cpu_measure()\n",
        "\n",
        "            # Extract prediction (median quantile)\n",
        "            pred_last = float(y_hat[0, median_idx, 0].item())\n",
        "\n",
        "            # Calculate metrics\n",
        "            rmse_val = rmse_np([true_last], [pred_last])\n",
        "\n",
        "            # FLOPS estimation\n",
        "            sequence_len = len(history)\n",
        "            flops = count_transformer_flops(pipe.model, sequence_len)\n",
        "\n",
        "            # CPU power measurement\n",
        "            avg_cpu_inf = (cpu_before_inf + cpu_after_inf) / 2\n",
        "\n",
        "            # Store results\n",
        "            results.append({\n",
        "                \"sector\": sector,\n",
        "                \"actual_value\": true_last,\n",
        "                \"predicted_value\": pred_last,\n",
        "                \"RMSE\": rmse_val,\n",
        "                \"inference_time_s\": inference_time,\n",
        "                \"FLOPS_estimated\": flops,\n",
        "                \"cpu_inference_percent\": avg_cpu_inf,\n",
        "                \"sequence_length\": sequence_len,\n",
        "                \"n_observations\": len(y)\n",
        "            })\n",
        "\n",
        "            inference_times.append(inference_time)\n",
        "            cpu_measurements.append(avg_cpu_inf)\n",
        "            flops_list.append(flops)\n",
        "\n",
        "        except Exception as e:\n",
        "            errors += 1\n",
        "            if errors <= 3:  # Show first 3 errors\n",
        "                print(f\"     Error sector {sector}: {str(e)[:40]}...\")\n",
        "\n",
        "            results.append({\n",
        "                \"sector\": sector,\n",
        "                \"actual_value\": true_last,\n",
        "                \"predicted_value\": None,\n",
        "                \"RMSE\": None,\n",
        "                \"inference_time_s\": None,\n",
        "                \"FLOPS_estimated\": None,\n",
        "                \"cpu_inference_percent\": None,\n",
        "                \"sequence_length\": len(history),\n",
        "                \"n_observations\": len(y),\n",
        "                \"error\": str(e)\n",
        "            })\n",
        "\n",
        "    # Create results DataFrame\n",
        "    df_results = pd.DataFrame(results)\n",
        "    successful = df_results.dropna(subset=[\"RMSE\"])\n",
        "\n",
        "    # Calculate global metrics\n",
        "    if not successful.empty:\n",
        "        global_rmse = rmse_np(successful[\"actual_value\"].values,\n",
        "                            successful[\"predicted_value\"].values)\n",
        "        avg_inference_time = successful[\"inference_time_s\"].mean()\n",
        "        avg_flops = successful[\"FLOPS_estimated\"].mean()\n",
        "        avg_cpu = successful[\"cpu_inference_percent\"].mean()\n",
        "    else:\n",
        "        global_rmse = None\n",
        "        avg_inference_time = None\n",
        "        avg_flops = None\n",
        "        avg_cpu = None\n",
        "\n",
        "    print(f\"   Results: {len(successful)} successful predictions\")\n",
        "    print(f\"    Global RMSE: {global_rmse:.4f}\" if global_rmse else \"    No successful predictions\")\n",
        "    print(f\"    Avg inference time: {avg_inference_time:.6f}s\" if avg_inference_time else \"\")\n",
        "\n",
        "\n",
        "# Show best/worst predictions like other models\n",
        "    if not successful.empty:\n",
        "        successful_sorted = successful.sort_values(\"RMSE\")\n",
        "        print(f\"\\n    Top 5 best predictions (lowest RMSE):\")\n",
        "        best_5 = successful_sorted[[\"sector\", \"actual_value\", \"predicted_value\", \"RMSE\", \"inference_time_s\"]].head()\n",
        "        for _, row in best_5.iterrows():\n",
        "            print(f\"      {row['sector']}: Real={row['actual_value']:.2f}, Pred={row['predicted_value']:.2f}, RMSE={row['RMSE']:.4f}, Time={row['inference_time_s']:.6f}s\")\n",
        "\n",
        "        print(f\"\\n   Top 5 worst predictions (highest RMSE):\")\n",
        "        worst_5 = successful_sorted[[\"sector\", \"actual_value\", \"predicted_value\", \"RMSE\", \"inference_time_s\"]].tail()\n",
        "        for _, row in worst_5.iterrows():\n",
        "            print(f\"      {row['sector']}: Real={row['actual_value']:.2f}, Pred={row['predicted_value']:.2f}, RMSE={row['RMSE']:.4f}, Time={row['inference_time_s']:.6f}s\")\n",
        "\n",
        "    # Summary for comparison\n",
        "    model_summary = {\n",
        "        \"model\": model_name.split(\"/\")[-1],  # Extract model name\n",
        "        \"global_rmse\": global_rmse,\n",
        "        \"avg_inference_time_s\": avg_inference_time,\n",
        "        \"model_load_time_s\": load_time,\n",
        "        \"avg_flops\": avg_flops,\n",
        "        \"avg_power_cpu_percent\": avg_cpu,\n",
        "        \"model_size_mb\": model_size_mb,\n",
        "        \"n_predictions\": len(successful),\n",
        "        \"success_rate_percent\": len(successful)/(len(successful)+errors)*100,\n",
        "        \"device\": str(model_device),\n",
        "        \"bf16_enabled\": USE_BF16\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"results_df\": df_results.sort_values(\"RMSE\", na_position=\"last\"),\n",
        "        \"summary\": model_summary,\n",
        "        \"successful_df\": successful\n",
        "    }\n",
        "\n",
        "# 7. RUN ALL CHRONOS MODELS\n",
        "print(f\"\\n🎯 Starting analysis of {len(models)} Chronos models...\")\n",
        "\n",
        "all_results = {}\n",
        "all_summaries = {}\n",
        "\n",
        "for i, model_name in enumerate(models):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"📈 MODEL {i+1}/{len(models)}: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    try:\n",
        "        result = run_bolt_for_model(model_name, df)\n",
        "\n",
        "        # Store results\n",
        "        all_results[model_name] = result[\"results_df\"]\n",
        "        all_summaries[model_name] = result[\"summary\"]\n",
        "\n",
        "        # Save individual CSV\n",
        "        model_short = model_name.replace(\"/\", \"_\")\n",
        "        csv_filename = f\"Chronos_{model_short}_complete_results.csv\"\n",
        "        result[\"results_df\"].to_csv(csv_filename, index=False)\n",
        "        print(f\"   💾 Saved: {csv_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    Failed to run {model_name}: {e}\")\n",
        "        all_summaries[model_name] = {\n",
        "            \"model\": model_name.split(\"/\")[-1],\n",
        "            \"global_rmse\": None,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "# 8. FINAL COMPARISON AND RESULTS\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\" CHRONOS BOLT MODELS - FINAL COMPARISON\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_data = []\n",
        "for model_name, summary in all_summaries.items():\n",
        "    if summary.get(\"global_rmse\") is not None:\n",
        "        comparison_data.append({\n",
        "            \"Model\": summary[\"model\"],\n",
        "            \"Global_RMSE\": f\"{summary['global_rmse']:.4f}\",\n",
        "            \"Avg_Inference_Time_s\": f\"{summary['avg_inference_time_s']:.6f}\",\n",
        "            \"Avg_FLOPS\": f\"{summary['avg_flops']:.0f}\",\n",
        "            \"Model_Size_MB\": f\"{summary['model_size_mb']:.1f}\",\n",
        "            \"Success_Rate_%\": f\"{summary['success_rate_percent']:.1f}\",\n",
        "            \"N_Predictions\": summary[\"n_predictions\"]\n",
        "        })\n",
        "\n",
        "if comparison_data:\n",
        "    df_comparison = pd.DataFrame(comparison_data)\n",
        "    print(df_comparison.to_string(index=False))\n",
        "\n",
        "    # Save comparison\n",
        "    df_comparison.to_csv(\"Chronos_models_comparison.csv\", index=False)\n",
        "    print(f\"\\n Comparison saved: Chronos_models_comparison.csv\")\n",
        "\n",
        "    # Store summaries for final project comparison\n",
        "    chronos_summaries = all_summaries\n",
        "    print(f\"\\n All summaries stored in 'chronos_summaries' for final comparison!\")\n",
        "else:\n",
        "    print(\" No successful model runs for comparison.\")\n",
        "\n",
        "print(f\"\\n Chronos analysis complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrzLklGsetFx",
        "outputId": "e8cf8ccf-32f1-4639-fc12-5e0e59dd015e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Data verification...\n",
            "DataFrame loaded: (24486, 4)\n",
            "Columns: ['secteur', 'site', 'tstamp', 'trafic_mbps']\n",
            "Number of unique sectors: 86\n",
            "\n",
            "🔧 Configuration:\n",
            "   • Device: cuda\n",
            "   • BF16: True\n",
            "   • Models to test: 4\n",
            "\n",
            "🎯 Starting analysis of 4 Chronos models...\n",
            "\n",
            "============================================================\n",
            "📈 MODEL 1/4: amazon/chronos-bolt-tiny\n",
            "============================================================\n",
            "\n",
            "🚀 Loading amazon/chronos-bolt-tiny on cuda...\n",
            "   • Model size: 33.0 MB\n",
            "   • Load time: 1.163s\n",
            "   • Processing 86 sectors...\n",
            "     📊 Progress: 1/86 (1.2%)\n",
            "     📊 Progress: 10/86 (11.6%)\n",
            "     📊 Progress: 50/86 (58.1%)\n",
            "   ✅ Results: 86 successful predictions\n",
            "   ✅ Global RMSE: 8.2450\n",
            "   ✅ Avg inference time: 0.018732s\n",
            "\n",
            "   🏆 Top 5 best predictions (lowest RMSE):\n",
            "      T36870B: Real=5.58, Pred=5.57, RMSE=0.0020, Time=0.017170s\n",
            "      T70747B: Real=14.65, Pred=14.63, RMSE=0.0193, Time=0.020658s\n",
            "      T78279B: Real=2.47, Pred=2.39, RMSE=0.0800, Time=0.017307s\n",
            "      T76995B: Real=6.70, Pred=6.60, RMSE=0.0948, Time=0.017961s\n",
            "      T78273A: Real=21.79, Pred=21.63, RMSE=0.1587, Time=0.018880s\n",
            "\n",
            "   ⚠️ Top 5 worst predictions (highest RMSE):\n",
            "      T78258C: Real=61.24, Pred=48.30, RMSE=12.9461, Time=0.018112s\n",
            "      T78259C: Real=75.05, Pred=49.09, RMSE=25.9596, Time=0.017757s\n",
            "      T70744B: Real=98.00, Pred=68.39, RMSE=29.6161, Time=0.019136s\n",
            "      T78258B: Real=93.26, Pred=62.38, RMSE=30.8727, Time=0.029221s\n",
            "      T78273C: Real=106.27, Pred=74.35, RMSE=31.9169, Time=0.019622s\n",
            "   💾 Saved: Chronos_amazon_chronos-bolt-tiny_complete_results.csv\n",
            "\n",
            "============================================================\n",
            "📈 MODEL 2/4: amazon/chronos-bolt-mini\n",
            "============================================================\n",
            "\n",
            "🚀 Loading amazon/chronos-bolt-mini on cuda...\n",
            "   • Model size: 81.0 MB\n",
            "   • Load time: 1.219s\n",
            "   • Processing 86 sectors...\n",
            "     📊 Progress: 1/86 (1.2%)\n",
            "     📊 Progress: 10/86 (11.6%)\n",
            "     📊 Progress: 50/86 (58.1%)\n",
            "   ✅ Results: 86 successful predictions\n",
            "   ✅ Global RMSE: 6.7144\n",
            "   ✅ Avg inference time: 0.018604s\n",
            "\n",
            "   🏆 Top 5 best predictions (lowest RMSE):\n",
            "      T78279B: Real=2.47, Pred=2.44, RMSE=0.0337, Time=0.017284s\n",
            "      T70735B: Real=20.98, Pred=20.74, RMSE=0.2396, Time=0.017467s\n",
            "      T70731B: Real=42.15, Pred=41.90, RMSE=0.2536, Time=0.018577s\n",
            "      T70721C: Real=1.60, Pred=1.31, RMSE=0.2864, Time=0.018501s\n",
            "      T70735A: Real=26.89, Pred=26.57, RMSE=0.3223, Time=0.016982s\n",
            "\n",
            "   ⚠️ Top 5 worst predictions (highest RMSE):\n",
            "      T78258C: Real=61.24, Pred=48.30, RMSE=12.9461, Time=0.017368s\n",
            "      T78273C: Real=106.27, Pred=85.84, RMSE=20.4279, Time=0.029171s\n",
            "      T78259C: Real=75.05, Pred=54.06, RMSE=20.9875, Time=0.016612s\n",
            "      T78258B: Real=93.26, Pred=70.13, RMSE=23.1263, Time=0.018835s\n",
            "      T70744B: Real=98.00, Pred=74.34, RMSE=23.6597, Time=0.017465s\n",
            "   💾 Saved: Chronos_amazon_chronos-bolt-mini_complete_results.csv\n",
            "\n",
            "============================================================\n",
            "📈 MODEL 3/4: amazon/chronos-bolt-small\n",
            "============================================================\n",
            "\n",
            "🚀 Loading amazon/chronos-bolt-small on cuda...\n",
            "   • Model size: 182.0 MB\n",
            "   • Load time: 1.241s\n",
            "   • Processing 86 sectors...\n",
            "     📊 Progress: 1/86 (1.2%)\n",
            "     📊 Progress: 10/86 (11.6%)\n",
            "     📊 Progress: 50/86 (58.1%)\n",
            "   ✅ Results: 86 successful predictions\n",
            "   ✅ Global RMSE: 6.9303\n",
            "   ✅ Avg inference time: 0.023920s\n",
            "\n",
            "   🏆 Top 5 best predictions (lowest RMSE):\n",
            "      T36870B: Real=5.58, Pred=5.52, RMSE=0.0566, Time=0.024700s\n",
            "      T70735B: Real=20.98, Pred=21.06, RMSE=0.0827, Time=0.022202s\n",
            "      T78279B: Real=2.47, Pred=2.38, RMSE=0.0925, Time=0.022759s\n",
            "      T70735A: Real=26.89, Pred=26.76, RMSE=0.1313, Time=0.022707s\n",
            "      T78273A: Real=21.79, Pred=21.63, RMSE=0.1587, Time=0.023332s\n",
            "\n",
            "   ⚠️ Top 5 worst predictions (highest RMSE):\n",
            "      T70725A: Real=39.34, Pred=52.14, RMSE=12.7996, Time=0.027697s\n",
            "      T78273C: Real=106.27, Pred=89.28, RMSE=16.9873, Time=0.022347s\n",
            "      T78259C: Real=75.05, Pred=52.82, RMSE=22.2305, Time=0.023892s\n",
            "      T70744B: Real=98.00, Pred=75.75, RMSE=22.2518, Time=0.022489s\n",
            "      T78258B: Real=93.26, Pred=65.72, RMSE=27.5414, Time=0.033413s\n",
            "   💾 Saved: Chronos_amazon_chronos-bolt-small_complete_results.csv\n",
            "\n",
            "============================================================\n",
            "📈 MODEL 4/4: amazon/chronos-bolt-base\n",
            "============================================================\n",
            "\n",
            "🚀 Loading amazon/chronos-bolt-base on cuda...\n",
            "   • Model size: 783.1 MB\n",
            "   • Load time: 1.589s\n",
            "   • Processing 86 sectors...\n",
            "     📊 Progress: 1/86 (1.2%)\n",
            "     📊 Progress: 10/86 (11.6%)\n",
            "     📊 Progress: 50/86 (58.1%)\n",
            "   ✅ Results: 86 successful predictions\n",
            "   ✅ Global RMSE: 8.0819\n",
            "   ✅ Avg inference time: 0.040170s\n",
            "\n",
            "   🏆 Top 5 best predictions (lowest RMSE):\n",
            "      T70731B: Real=42.15, Pred=42.19, RMSE=0.0439, Time=0.039860s\n",
            "      T78279B: Real=2.47, Pred=2.36, RMSE=0.1050, Time=0.039084s\n",
            "      T70721A: Real=3.75, Pred=3.61, RMSE=0.1444, Time=0.038922s\n",
            "      T70738C: Real=54.67, Pred=54.81, RMSE=0.1492, Time=0.039897s\n",
            "      T76995B: Real=6.70, Pred=6.90, RMSE=0.2043, Time=0.038468s\n",
            "\n",
            "   ⚠️ Top 5 worst predictions (highest RMSE):\n",
            "      T78258C: Real=61.24, Pred=45.79, RMSE=15.4488, Time=0.039810s\n",
            "      T78259C: Real=75.05, Pred=52.32, RMSE=22.7277, Time=0.040248s\n",
            "      T78273C: Real=106.27, Pred=81.91, RMSE=24.3600, Time=0.038455s\n",
            "      T70744B: Real=98.00, Pred=71.85, RMSE=26.1505, Time=0.039133s\n",
            "      T78258B: Real=93.26, Pred=57.02, RMSE=36.2383, Time=0.039887s\n",
            "   💾 Saved: Chronos_amazon_chronos-bolt-base_complete_results.csv\n",
            "\n",
            "============================================================\n",
            "📊 CHRONOS BOLT MODELS - FINAL COMPARISON\n",
            "============================================================\n",
            "             Model Global_RMSE Avg_Inference_Time_s    Avg_FLOPS Model_Size_MB Success_Rate_%  N_Predictions\n",
            " chronos-bolt-tiny      8.2450             0.018732   4909888298          33.0          100.0             86\n",
            " chronos-bolt-mini      6.7144             0.018604  12050249823          81.0          100.0             86\n",
            "chronos-bolt-small      6.9303             0.023920  27077199777         182.0          100.0             86\n",
            " chronos-bolt-base      8.0819             0.040170 116491801005         783.1          100.0             86\n",
            "\n",
            "💾 Comparison saved: Chronos_models_comparison.csv\n",
            "\n",
            "🎯 All summaries stored in 'chronos_summaries' for final comparison!\n",
            "\n",
            "🎉 Chronos analysis complete!\n"
          ]
        }
      ]
    }
  ]
}